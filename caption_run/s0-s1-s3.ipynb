{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "s0_0_img_retrival\n",
    "检索指定目录下所有指定文件(图片),保存到txt中\n",
    "'''\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# 定义\n",
    "file_type = 'jpg'\n",
    "retrival_path = '~/LMM_caption/origin_input/train_clip_pic_16'\n",
    "output_txt = '~/LMM_caption/origin_input/train_clip_pic_16.txt'\n",
    "\n",
    "# glob检索\n",
    "file_list = glob(f\"{retrival_path}/*.{file_type}\")\n",
    "\n",
    "# 保存到txt中\n",
    "with open(output_txt, 'a') as f:\n",
    "    for file in file_list:\n",
    "        f.write(file + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "s0_1_split_json\n",
    "将大的json文件拆分成单个对应json文件\n",
    "'''\n",
    "import json\n",
    "import os\n",
    "\n",
    "# input_json = '~/LMM_caption/test.json'\n",
    "input_json = '~/LMM_caption/origin_input/73_train.json'\n",
    "output_json_path = '~/LMM_caption/origin_input/train_clip_pic_16'\n",
    "# 打开 JSON 文件\n",
    "with open(input_json, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# 遍历 JSON 文件中的每个字典\n",
    "for i, dic in enumerate(data):\n",
    "    # 获取字典中的 'image' 属性，假设它是一个图片的 URL\n",
    "    img_url = dic['image']\n",
    "    # 从 URL 中获取图片的文件名，假设它是以 .jpg 结尾的\n",
    "    img_name = img_url.split('/')[-1]\n",
    "    img_name_prefix = img_name.split('.')[0]\n",
    "\n",
    "    # 将字典转换为 JSON 格式，并保存在新的文件夹中，以 i.json 为文件名\n",
    "    output_json = os.path.join(output_json_path, f'{img_name_prefix}.json')\n",
    "    with open(output_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(dic, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# '''\n",
    "# s0_2_split_img\n",
    "# 将图片分成n份以便进行多进程推理(sh文件)\n",
    "# '''\n",
    "\n",
    "# funcs\n",
    "doMakeDir(){\n",
    "    path=$1\n",
    "    if [ ! -d $path ]\n",
    "    then \n",
    "        mkdir -p $path\n",
    "    fi\n",
    "}\n",
    "# 指定pwd\n",
    "path='~/LMM_caption/split_file' \n",
    "cd $path\n",
    "name='train_clip_pic_16'\n",
    "doMakeDir \"${path}/${name}\"\n",
    "cd \"${name}\"\n",
    "\n",
    "# 定义输入txt\n",
    "input_txt=\"${name}.txt\"\n",
    "# 拷贝到当前目录\n",
    "cp \"~/LMM_caption/origin_input/${input_txt}\" ./\n",
    "# 获取总长度\n",
    "total_lens=$(wc -l < $input_txt) \n",
    "# 分成n份\n",
    "len_per_file=$(echo \"$total_lens / 10\" | bc)\n",
    "# split -d指定输出前缀 -a指定输出后缀输出长度 -l指定输入文件\n",
    "split -d -a 2 -l $len_per_file $input_txt slice00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "s1_info_copy\n",
    "单进程简单复制json无需变动信息\n",
    "'''\n",
    "\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "# input_txt\n",
    "input_txt = f'~/LMM_caption/split_file/train_clip_pic_16/train_clip_pic_16.txt'\n",
    "\n",
    "# func\n",
    "def get_img_reso(img_path):\n",
    "    with Image.open(img_path) as img:\n",
    "        return img.size\n",
    "\n",
    "# copy info\n",
    "if os.path.exists(input_txt):\n",
    "    with open(input_txt, 'r') as f:\n",
    "        i = 0\n",
    "        content = {}\n",
    "        copy_keys = ['image', 'caption', 'translation', 'relationship']\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            line_prefix, line_postfix = os.path.splitext(line)\n",
    "            # get img_reso\n",
    "            width, height = get_img_reso(line)\n",
    "\n",
    "            # get input_json/output_json\n",
    "            input_json = line_prefix + '.json'\n",
    "            output_json = line_prefix + '_output.json'\n",
    "\n",
    "            # get input_json's content\n",
    "            if os.path.exists(input_json):\n",
    "                with open(input_json, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    for key in copy_keys:\n",
    "                        if key in data:\n",
    "                            content[key] = data[key]\n",
    "                        else:\n",
    "                            print(f'Warning: Key {key} not found in {input_json}')\n",
    "\n",
    "                # add other keys that do not need to be changed either\n",
    "                content['id'] = i\n",
    "                content['annotator'] = 2\n",
    "                content['annotator_id'] = i\n",
    "                content['created_at'] = \"2024-01-07T03:01:10.604652Z\"\n",
    "                content['updated_at'] = \"2024-01-07T03:01:10.604652Z\"\n",
    "                content['lead_time'] = 348.555\n",
    "                content['Label'] = [\n",
    "                    {\n",
    "                        \"x\": 0,\n",
    "                        \"y\": 0,\n",
    "                        \"width\": 10,\n",
    "                        \"height\": 10,\n",
    "                        \"rotation\": 0,\n",
    "                        \"rectanglelabels\": [\n",
    "                            \"Daytime\"\n",
    "                        ],\n",
    "                        \"original_width\": width,\n",
    "                        \"original_height\": height\n",
    "                    }\n",
    "                ]\n",
    "                i += 1\n",
    "\n",
    "                # copy to output_json\n",
    "                with open(output_json, 'w') as f:\n",
    "                    json.dump(content, f, indent=4, ensure_ascii=False)\n",
    "            else:\n",
    "                print(f'Error: File {input_json} not found')\n",
    "else:\n",
    "    print(f'Error: File {input_txt} not found')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "s3_merge_json\n",
    "合并所有json\n",
    "'''\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# definition\n",
    "input_path = f'~/LMM_caption/origin_input/train_clip_pic_16'\n",
    "output_path = f'~/LMM_caption/json_dir/train_clip_pic_16/output_final.json'\n",
    "files = glob.glob(os.path.join(input_path, '*output.json'))  # Remove the extra slash here\n",
    "merged_data = []\n",
    "\n",
    "# traversal\n",
    "for file in files:\n",
    "    # 读取 JSON 文件\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    # 合并数据\n",
    "    merged_data.append(data)\n",
    "\n",
    "# save to final json\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(merged_data, f, indent=4, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelscope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
